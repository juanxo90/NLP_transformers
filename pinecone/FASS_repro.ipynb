{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAISS intro \n",
    "\n",
    "Reproduction of the code in [FAISS tutorial](https://www.pinecone.io/learn/faiss-tutorial/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_ID</th>\n",
       "      <th>sentence_A</th>\n",
       "      <th>sentence_B</th>\n",
       "      <th>relatedness_score</th>\n",
       "      <th>entailment_judgment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>A group of boys in a yard is playing and a man...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A group of children is playing in the house an...</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The young boys are playing outdoors and the ma...</td>\n",
       "      <td>The kids are playing outdoors near a man with ...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>ENTAILMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>The kids are playing outdoors near a man with ...</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>The young boys are playing outdoors and the ma...</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>3.7</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pair_ID                                         sentence_A  \\\n",
       "0        1  A group of kids is playing in a yard and an ol...   \n",
       "1        2  A group of children is playing in the house an...   \n",
       "2        3  The young boys are playing outdoors and the ma...   \n",
       "3        5  The kids are playing outdoors near a man with ...   \n",
       "4        9  The young boys are playing outdoors and the ma...   \n",
       "\n",
       "                                          sentence_B  relatedness_score  \\\n",
       "0  A group of boys in a yard is playing and a man...                4.5   \n",
       "1  A group of kids is playing in a yard and an ol...                3.2   \n",
       "2  The kids are playing outdoors near a man with ...                4.7   \n",
       "3  A group of kids is playing in a yard and an ol...                3.4   \n",
       "4  A group of kids is playing in a yard and an ol...                3.7   \n",
       "\n",
       "  entailment_judgment  \n",
       "0             NEUTRAL  \n",
       "1             NEUTRAL  \n",
       "2          ENTAILMENT  \n",
       "3             NEUTRAL  \n",
       "4             NEUTRAL  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = requests.get('https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/sick2014/SICK_train.txt')\n",
    "# create dataframe\n",
    "data = pd.read_csv(StringIO(res.text), sep='\\t')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A group of kids is playing in a yard and an old man is standing in the background',\n",
       " 'A group of children is playing in the house and there is no man standing in the background',\n",
       " 'The young boys are playing outdoors and the man is smiling nearby',\n",
       " 'The kids are playing outdoors near a man with a smile',\n",
       " 'The young boys are playing outdoors and the man is smiling nearby']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we take all samples from both sentence A and B\n",
    "sentences = data['sentence_A'].tolist()\n",
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4802"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we take all samples from both sentence A and B\n",
    "sentences = data['sentence_A'].tolist()\n",
    "sentence_b = data['sentence_B'].tolist()\n",
    "sentences.extend(sentence_b)  # merge them\n",
    "len(set(sentences))  # together we have ~4.5K unique sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting more data\n",
    "\n",
    "urls = [\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2012/MSRpar.train.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2012/MSRpar.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2012/OnWN.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2013/OnWN.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2014/OnWN.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2014/images.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2015/images.test.tsv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each of these dataset have the same structure, so we loop through each creating our sentences data\n",
    "for url in urls:\n",
    "    res = requests.get(url)\n",
    "    # extract to dataframe\n",
    "    data_1 = pd.read_csv(StringIO(res.text), sep='\\t', header=None, on_bad_lines='skip')\n",
    "    # add to columns 1 and 2 to sentences list\n",
    "    sentences.extend(data_1[1].tolist())\n",
    "    sentences.extend(data_1[2].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14505"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14504"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing nan and duplicated\n",
    "sentences = pd.Series([word for word in list(set(sentences)) if type(word) is str])\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14504, 768)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a BERT model using sentence transformers\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "# initialize sentence transformer model\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "# create sentence embeddings\n",
    "sentence_embeddings = model.encode(sentences.to_list())\n",
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan and simple similarity search using IndexFlatL2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the vector size \n",
    "d = sentence_embeddings.shape[1]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating the index\n",
    "index = faiss.IndexFlatL2(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# is the index trained?\n",
    "index.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14504"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# addeding our embeddings (vectorized text)\n",
    "index.add(sentence_embeddings)\n",
    "# see the total\n",
    "index.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# searching similarities the k nearest neigbors between xq and our data \n",
    "k = 4\n",
    "xq = model.encode([\"Someone sprints with a football\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9884   340 12395  5399]]\n",
      "CPU times: user 17 ms, sys: 28 µs, total: 17 ms\n",
      "Wall time: 15.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D, I = index.search(xq, k)  # search\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9884     A group of football players is running in the ...\n",
       "340      A group of people playing football is running ...\n",
       "12395            Two groups of people are playing football\n",
       "5399     A person playing football is running past an o...\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify our text\n",
    "sentences.iloc[I[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the numerical vector from faiss\n",
    "# we have 4 vectors to return (k) - so we initialize a zero array to hold them\n",
    "vecs = np.zeros((k, d))\n",
    "# then iterate through each ID from I and add the reconstructed vector to our zero-array\n",
    "for i, val in enumerate(I[0].tolist()):\n",
    "    vecs[i, :] = index.reconstruct(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 768)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01627034,  0.22325909, -0.15037404, -0.30747247, -0.27122435,\n",
       "       -0.10593174, -0.06460953,  0.04738246, -0.73349065, -0.37657726,\n",
       "       -0.76762778,  0.16902889,  0.53107685,  0.51176643,  1.14415836,\n",
       "       -0.08562846, -0.67240065, -0.96637088,  0.02545462, -0.2155983 ,\n",
       "       -1.25656593, -0.82982177, -0.09825007, -0.21850885,  0.50610268,\n",
       "        0.10527948,  0.50396878,  0.65242952, -1.39458692,  0.65847504,\n",
       "       -0.21525346, -0.22487436,  0.81818366,  0.08464289, -0.76141709,\n",
       "       -0.28928319, -0.09825802, -0.7304616 ,  0.07855845, -0.84354568,\n",
       "       -0.59242058,  0.77471358, -1.20920539, -0.22757953, -1.30733609,\n",
       "       -0.23081474, -1.31322527,  0.01629097, -0.97285479,  0.19308148,\n",
       "        0.47424552,  1.18920887, -1.96741259, -0.70061088, -0.29638764,\n",
       "        0.60533708,  0.62407476, -0.70340389, -0.86754155,  0.17673104,\n",
       "       -0.19170557, -0.02951936,  0.22623543, -0.1669542 , -0.80402559,\n",
       "       -0.45918953,  0.69675452, -0.24928206, -1.01478684, -0.9217453 ,\n",
       "       -0.33842683, -0.39296773, -0.8373487 , -0.11479253,  0.46049693,\n",
       "       -1.45211208,  0.60310441,  0.38696313, -0.04061206,  0.00453173,\n",
       "        0.24117853,  0.05396278,  0.07506417,  1.05115879,  0.12383965,\n",
       "       -0.71281075,  0.11722887,  0.52238196, -0.04581172,  0.26827082,\n",
       "        0.85985428, -0.3566989 , -0.646671  , -0.54357928, -0.04310531,\n",
       "        0.95139188, -0.15605707, -0.49625334, -0.11140195,  0.15610136])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs[0][:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partitioning the index (IVFFlat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlist = 50  # how many cells\n",
    "quantizer = faiss.IndexFlatL2(d)\n",
    "index = faiss.IndexIVFFlat(quantizer, d, nlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.train(sentence_embeddings)\n",
    "index.is_trained  # check if index is now trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14504"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.add(sentence_embeddings)\n",
    "index.ntotal  # number of embeddings indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9884   340 12395  5399]]\n",
      "CPU times: user 1.01 ms, sys: 973 µs, total: 1.98 ms\n",
      "Wall time: 1.09 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D, I = index.search(xq, k)  # search\n",
    "print(I)\n",
    "# FlatL2 result [[ 9884   340 12395  5399]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9884     A group of football players is running in the ...\n",
       "340      A group of people playing football is running ...\n",
       "12395            Two groups of people are playing football\n",
       "5399     A person playing football is running past an o...\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify our text\n",
    "sentences.iloc[I[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increasin the nprobe \n",
    "index.nprobe = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9884   340 12395  5399]]\n",
      "CPU times: user 3.1 ms, sys: 2.57 ms, total: 5.67 ms\n",
      "Wall time: 4.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D, I = index.search(xq, k)  # search\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the vector reconstruction we need to add direct map\n",
    "index.make_direct_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.28991434,  0.54199064, -0.27298486,  0.10417995, -0.33969614,\n",
       "       -0.4506219 ,  0.07291928, -0.3549848 , -0.8369879 , -0.32433224,\n",
       "       -1.2478453 ,  0.10843043,  0.29072765,  0.21705268,  0.60392576,\n",
       "        0.06538893, -0.6706807 , -0.90537196,  0.02427153, -0.24707308,\n",
       "       -1.2672976 , -0.97827107,  0.15829204, -0.13239901,  0.7912185 ,\n",
       "        0.51121765,  0.05511359,  0.7540963 , -1.5350547 ,  0.53369606,\n",
       "       -0.04551981, -0.18737014,  0.6334436 ,  0.23146886, -1.0518087 ,\n",
       "       -0.7283868 ,  0.82900846, -0.9575755 ,  0.272913  ,  0.21210498,\n",
       "       -0.4041685 ,  0.977175  , -1.1903669 , -0.5085015 , -0.8816648 ,\n",
       "       -0.03428968, -0.8209083 , -0.07884365, -0.637655  ,  0.01346982,\n",
       "        0.7326747 ,  1.2296643 , -1.6466395 , -1.2337519 , -0.65219116,\n",
       "        0.15154126,  0.5415216 , -0.52801603, -1.2121469 , -0.17640916,\n",
       "       -1.4374218 , -0.17282893, -0.01257554, -0.3825809 , -0.3267509 ,\n",
       "       -0.30086067,  0.15054575, -0.0587858 , -1.2200756 , -1.020916  ,\n",
       "       -0.57897055, -0.8951366 , -0.54111475, -0.14987203,  0.8750257 ,\n",
       "       -1.1502836 ,  0.49387982,  0.34740993, -0.0048365 ,  0.208226  ,\n",
       "       -0.37572056,  0.36779052, -0.04147116,  0.3778324 ,  0.6454976 ,\n",
       "       -0.15964709,  0.19490625,  0.38110125,  0.09328865,  0.10306262,\n",
       "        0.45845467,  0.06453434, -0.43549317, -0.82809967, -0.18975511,\n",
       "        0.6828214 ,  0.37775025, -0.30457246, -0.07370135, -0.19008242],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.reconstruct(7460)[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization\n",
    "\n",
    "it works in this way\n",
    "1. We split the original vector into several subvectors.\n",
    "2. For each set of subvectors, we perform a clustering operation — creating multiple centroids for each sub-vector set.\n",
    "3. In our vector of sub-vectors, we replace each sub-vector with the ID of it’s nearest set-specific centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the worflow\n",
    "m = 8  # number of centroid IDs in final compressed vectors\n",
    "bits = 8 # number of bits in each centroid\n",
    "\n",
    "quantizer = faiss.IndexFlatL2(d)\n",
    "index = faiss.IndexIVFPQ(quantizer, d, nlist, m, bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the index\n",
    "index.train(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding our vectors\n",
    "index.add(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the nbrobe\n",
    "index.nprobe = 10  # align to previous IndexIVFFlat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 340 1121 1304  174]]\n",
      "CPU times: user 1.64 ms, sys: 0 ns, total: 1.64 ms\n",
      "Wall time: 1.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D, I = index.search(xq, k)\n",
    "print(I)\n",
    "\n",
    "# FlatL2 result [[ 9884   340 12395  5399]] (15.4 ms) \n",
    "# IVFFlat result nbrobe = 10 [[ 9884   340 12395  5399]] (4.6 ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kraken-py-38",
   "language": "python",
   "name": "kraken-py-38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
